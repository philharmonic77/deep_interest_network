{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6a6d97",
   "metadata": {},
   "source": [
    "**背景：**  \n",
    "  \n",
    "后面继续介绍除了之前第1、2部分模型结构之外的其他内容，包括：\n",
    "1. 实战中的data load\n",
    "2. callback和tensorboard\n",
    "3. 自定义training loop\n",
    "4. distributed training\n",
    "5. model save and load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bcdc6",
   "metadata": {},
   "source": [
    "## [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord)\n",
    "\n",
    "**关于TFRecord和tf.train.Example的几点备注：**\n",
    "1. The TFRecord format is a simple format for storing a sequence of binary records.\n",
    "2. The tf.train.Example is a method of serializing dictionaries to byte-strings. \n",
    "3. There is no need to convert existing code to use TFRecords, unless you are using tf.data and reading data is still the bottleneck to training. \n",
    "4. There is no requirement to use tf.train.Example in TFRecord files.\n",
    "5. [official example](https://github.com/tensorflow/models/blob/8367cf6dabe11adf7628541706b660821f397dce/research/slim/datasets/download_and_convert_flowers.py)：Downloads and converts Flowers data to TFRecords of TF-Example protos.\n",
    "\n",
    "以下摘录tf.data相关的内容："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64adf1",
   "metadata": {},
   "source": [
    "### 把标准standard TensorFlow type转化为tf.train.Example兼容的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c242044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494ca3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible with tf.train.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba55c20",
   "metadata": {},
   "source": [
    "### 创建一条tf.train.Example message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a231df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "        'feature0': _int64_feature(feature0),\n",
    "        'feature1': _int64_feature(feature1),\n",
    "        'feature2': _bytes_feature(feature2),\n",
    "        'feature3': _float_feature(feature3),\n",
    "    }\n",
    "  \n",
    "    # Create a Features message using tf.train.Example.\n",
    "  \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString() # proto messages serialized to a binary-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c25d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 01:23:18.612979: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-01 01:23:18.613378: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04[\\xd3|?\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n",
    "serialized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a870e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"feature0\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature1\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 4\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature2\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"goat\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature3\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 0.9876000285148621\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果想要反序列化：\n",
    "example_proto = tf.train.Example.FromString(serialized_example)\n",
    "example_proto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b92e7",
   "metadata": {},
   "source": [
    "### 使用**tf.data写**TFRecord文件  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f394d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (), (), ()), types: (tf.bool, tf.int64, tf.string, tf.float64)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个数据集 \n",
    "\n",
    "# The number of observations in the dataset.\n",
    "n_observations = int(100)\n",
    "\n",
    "# Boolean feature, encoded as False or True.\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "\n",
    "# Integer feature, random from 0 to 4.\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "\n",
    "# String feature.\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "\n",
    "# Float feature, from a standard normal distribution.\n",
    "feature3 = np.random.randn(n_observations)\n",
    "\n",
    "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))\n",
    "features_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a847eb",
   "metadata": {},
   "source": [
    "  The mapped function must operate in TensorFlow graph mode—it must operate on and return tf.Tensors. **A non-tensor function, like serialize_example, can be wrapped with tf.py_function to make it compatible.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3953a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_example(f0,f1,f2,f3):\n",
    "    tf_string = tf.py_function(\n",
    "        serialize_example,\n",
    "        (f0, f1, f2, f3),  # Pass these args to the above function.\n",
    "        tf.string)      # The return type is `tf.string`.\n",
    "    return tf.reshape(tf_string, ()) # The result is a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddabcb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
    "serialized_features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9da6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 01:23:18.673492: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/test.tfrecord'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(serialized_features_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf52da0",
   "metadata": {},
   "source": [
    "### 使用**tf.data读**TFRecord文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a987fa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/test.tfrecord'\n",
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89cbfedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nS\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04y\\xf7\\x91>\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03'>\n"
     ]
    }
   ],
   "source": [
    "# At this point the dataset contains serialized tf.train.Example messages.\n",
    "for raw_record in raw_dataset.take(1):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e404875",
   "metadata": {},
   "source": [
    "把tf.train.Example解析成standard tensors："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd340f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=0.2850912>}\n"
     ]
    }
   ],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "for record in parsed_dataset.take(1):\n",
    "    print(repr(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826862f",
   "metadata": {},
   "source": [
    "### 多维数组的情形"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6948aa",
   "metadata": {},
   "source": [
    "以上代码都是针对scalar，如果遇到多维的情况，可以使用以下两个函数来进行序列化和解析：  \n",
    "- [tf.io.serialize_tensor](https://www.tensorflow.org/api_docs/python/tf/io/serialize_tensor)\n",
    "- [tf.io.parse_tensor](https://www.tensorflow.org/api_docs/python/tf/io/parse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbc8b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x02\"\\x08\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([1,2])\n",
    "serialized_t = tf.io.serialize_tensor(t)\n",
    "serialized_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "addb2812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes_list {\n",
       "  value: \"\\010\\003\\022\\004\\022\\002\\010\\002\\\"\\010\\001\\000\\000\\000\\002\\000\\000\\000\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _bytes_feature(t) 没有经过序列化的多维tensor，这样会报错\n",
    "_bytes_feature(serialized_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56d3954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.parse_tensor(\n",
    "    serialized_t, out_type=tf.int32 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0d1bf",
   "metadata": {},
   "source": [
    "## 从HDFS导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64541192",
   "metadata": {},
   "source": [
    "这部分假设已经有TFRecords在hdfs数据节点上了。**这里copy一份前面生成的TFRecord，并且重命名为test2.tfrecord用于测试。**  \n",
    "有一份[文档](https://medium.com/@matthewyeung/hadoop-file-system-with-tensorflow-dataset-api-13ce9aeaa107)供参考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a7e41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/test2.tfrecord'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(serialized_features_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795e1e8",
   "metadata": {},
   "source": [
    "### 使用[tf.data.Dataset.list_files](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files)基于通配符找到所有数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd095d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file match cnt: 2\n"
     ]
    }
   ],
   "source": [
    "#dataset_files=hdfs://NamenodeIP:Port/path/to/tfrecord_dir/*.tfrecord \n",
    "dataset_files=\"data/*.tfrecord\" \n",
    "dataset = tf.data.Dataset.list_files(dataset_files)\n",
    "print(\"file match cnt:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280df543",
   "metadata": {},
   "source": [
    "### 使用[tf.data.Dataset.interleave](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#interleave)\n",
    "进行数据交叉。跨文件shuffle，打乱得更彻底。  \n",
    "*Note: While large buffer_sizes shuffle more thoroughly, they can take a lot of memory, and significant time to fill. Consider using Dataset.interleave across files if this becomes a problem.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c013ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.interleave(\n",
    "    lambda x: tf.data.TFRecordDataset(x),\n",
    "    cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    deterministic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207abdde",
   "metadata": {},
   "source": [
    "### 解析tf.Example message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9ff9d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=0.2850912>}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(_parse_function)\n",
    "for record in dataset.take(1):\n",
    "    print(repr(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ebefa8",
   "metadata": {},
   "source": [
    "### batch + prefetch\n",
    "这里也支持对每个batch进行[padding](https://www.tensorflow.org/guide/data#simple_batching)。最后加入prefetch，可以改善延迟和吞吐量，但同时会消耗额外的内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1489766d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {feature0: (64,), feature1: (64,), feature2: (64,), feature3: (64,)}, types: {feature0: tf.int64, feature1: tf.int64, feature2: tf.string, feature3: tf.float32}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset = dataset.batch(64, drop_remainder=True).prefetch(2)\n",
    "batched_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00515b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf38",
   "language": "python",
   "name": "tf38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
